{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML_week9.ipynb","provenance":[],"authorship_tag":"ABX9TyPximQSeyUhkDmS5Fibnzcc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"QKX5UkzuemvM","executionInfo":{"status":"ok","timestamp":1636347212306,"user_tz":-540,"elapsed":628616,"user":{"displayName":"알고리즘ᄒᄒ","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14802428065096538144"}},"outputId":"553b7105-6d9b-4ed9-8409-50b7ddc03654"},"source":["from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n","\n","(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n","\n","train_scaled = train_input / 255.0\n","train_scaled = train_scaled.reshape(-1, 28*28)\n","\n","train_scaled, val_scaled, train_target, val_target = train_test_split(\n","    train_scaled, train_target, test_size=0.2, random_state=42)\n","\n","def model_fn(a_layer=None):\n","    model = keras.Sequential()\n","    model.add(keras.layers.Flatten(input_shape=(28, 28))) #784개\n","    model.add(keras.layers.Dense(100, activation='tanh')) #hidden layer1\n","    model.add(keras.layers.Dense(200, activation='tanh')) #hidden layer2\n","    model.add(keras.layers.Dense(300, activation='tanh')) #hidden layer3\n","\n","    if a_layer:\n","        model.add(a_layer)\n","    model.add(keras.layers.Dense(10, activation='softmax'))\n","    return model\n","\n","model = model_fn()\n","model.summary()\n","\n","\n","model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n","history = model.fit(train_scaled, train_target, epochs=100)\n","'''\n","plt.plot(history.history['loss'])\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.savefig('7_3-01', dpi=300)\n","plt.show()\n","'''\n"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_10\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten_10 (Flatten)         (None, 784)               0         \n","_________________________________________________________________\n","dense_34 (Dense)             (None, 100)               78500     \n","_________________________________________________________________\n","dense_35 (Dense)             (None, 200)               20200     \n","_________________________________________________________________\n","dense_36 (Dense)             (None, 300)               60300     \n","_________________________________________________________________\n","dense_37 (Dense)             (None, 10)                3010      \n","=================================================================\n","Total params: 162,010\n","Trainable params: 162,010\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_10_input'), name='flatten_10_input', description=\"created by layer 'flatten_10_input'\"), but it was called on an input with incompatible shape (32, 784).\n","WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_10_input'), name='flatten_10_input', description=\"created by layer 'flatten_10_input'\"), but it was called on an input with incompatible shape (32, 784).\n","1500/1500 [==============================] - 7s 5ms/step - loss: 0.5337 - accuracy: 0.8052\n","Epoch 2/100\n","1500/1500 [==============================] - 7s 5ms/step - loss: 0.4018 - accuracy: 0.8527\n","Epoch 3/100\n","1500/1500 [==============================] - 7s 5ms/step - loss: 0.3567 - accuracy: 0.8675\n","Epoch 4/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.3310 - accuracy: 0.8759\n","Epoch 5/100\n","1500/1500 [==============================] - 7s 5ms/step - loss: 0.3108 - accuracy: 0.8834\n","Epoch 6/100\n","1500/1500 [==============================] - 7s 5ms/step - loss: 0.2940 - accuracy: 0.8914\n","Epoch 7/100\n","1500/1500 [==============================] - 7s 5ms/step - loss: 0.2800 - accuracy: 0.8967\n","Epoch 8/100\n","1500/1500 [==============================] - 7s 5ms/step - loss: 0.2704 - accuracy: 0.8995\n","Epoch 9/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.2588 - accuracy: 0.9049\n","Epoch 10/100\n","1500/1500 [==============================] - 7s 4ms/step - loss: 0.2491 - accuracy: 0.9084\n","Epoch 11/100\n","1500/1500 [==============================] - 7s 4ms/step - loss: 0.2381 - accuracy: 0.9118\n","Epoch 12/100\n","1500/1500 [==============================] - 7s 4ms/step - loss: 0.2309 - accuracy: 0.9134\n","Epoch 13/100\n","1500/1500 [==============================] - 7s 4ms/step - loss: 0.2248 - accuracy: 0.9167\n","Epoch 14/100\n","1500/1500 [==============================] - 7s 5ms/step - loss: 0.2174 - accuracy: 0.9195\n","Epoch 15/100\n","1500/1500 [==============================] - 7s 4ms/step - loss: 0.2082 - accuracy: 0.9229\n","Epoch 16/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.2017 - accuracy: 0.9249\n","Epoch 17/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1961 - accuracy: 0.9267\n","Epoch 18/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1926 - accuracy: 0.9287\n","Epoch 19/100\n","1500/1500 [==============================] - 7s 4ms/step - loss: 0.1835 - accuracy: 0.9319\n","Epoch 20/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1773 - accuracy: 0.9353\n","Epoch 21/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1728 - accuracy: 0.9366\n","Epoch 22/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1681 - accuracy: 0.9383\n","Epoch 23/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1640 - accuracy: 0.9388\n","Epoch 24/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1574 - accuracy: 0.9420\n","Epoch 25/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1540 - accuracy: 0.9434\n","Epoch 26/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1493 - accuracy: 0.9448\n","Epoch 27/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1435 - accuracy: 0.9472\n","Epoch 28/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1401 - accuracy: 0.9492\n","Epoch 29/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1361 - accuracy: 0.9510\n","Epoch 30/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1333 - accuracy: 0.9521\n","Epoch 31/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1293 - accuracy: 0.9534\n","Epoch 32/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1264 - accuracy: 0.9536\n","Epoch 33/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1215 - accuracy: 0.9555\n","Epoch 34/100\n","1500/1500 [==============================] - 7s 4ms/step - loss: 0.1215 - accuracy: 0.9561\n","Epoch 35/100\n","1500/1500 [==============================] - 7s 5ms/step - loss: 0.1175 - accuracy: 0.9572\n","Epoch 36/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1108 - accuracy: 0.9611\n","Epoch 37/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1121 - accuracy: 0.9597\n","Epoch 38/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1082 - accuracy: 0.9622\n","Epoch 39/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1035 - accuracy: 0.9630\n","Epoch 40/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1029 - accuracy: 0.9632\n","Epoch 41/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0979 - accuracy: 0.9649\n","Epoch 42/100\n","1500/1500 [==============================] - 7s 5ms/step - loss: 0.0965 - accuracy: 0.9659\n","Epoch 43/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0917 - accuracy: 0.9676\n","Epoch 44/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0951 - accuracy: 0.9653\n","Epoch 45/100\n","1500/1500 [==============================] - 7s 4ms/step - loss: 0.0898 - accuracy: 0.9676\n","Epoch 46/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0882 - accuracy: 0.9682\n","Epoch 47/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0870 - accuracy: 0.9679\n","Epoch 48/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0865 - accuracy: 0.9689\n","Epoch 49/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0852 - accuracy: 0.9703\n","Epoch 50/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0845 - accuracy: 0.9695\n","Epoch 51/100\n","1500/1500 [==============================] - 7s 4ms/step - loss: 0.0811 - accuracy: 0.9708\n","Epoch 52/100\n","1500/1500 [==============================] - 7s 5ms/step - loss: 0.0780 - accuracy: 0.9727\n","Epoch 53/100\n","1500/1500 [==============================] - 7s 4ms/step - loss: 0.0770 - accuracy: 0.9730\n","Epoch 54/100\n","1500/1500 [==============================] - 7s 4ms/step - loss: 0.0762 - accuracy: 0.9725\n","Epoch 55/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0741 - accuracy: 0.9736\n","Epoch 56/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0723 - accuracy: 0.9739\n","Epoch 57/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0733 - accuracy: 0.9745\n","Epoch 58/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0724 - accuracy: 0.9739\n","Epoch 59/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0701 - accuracy: 0.9752\n","Epoch 60/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0720 - accuracy: 0.9753\n","Epoch 61/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0661 - accuracy: 0.9760\n","Epoch 62/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0674 - accuracy: 0.9761\n","Epoch 63/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0645 - accuracy: 0.9763\n","Epoch 64/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0672 - accuracy: 0.9756\n","Epoch 65/100\n","1500/1500 [==============================] - 7s 4ms/step - loss: 0.0640 - accuracy: 0.9777\n","Epoch 66/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0632 - accuracy: 0.9781\n","Epoch 67/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0634 - accuracy: 0.9776\n","Epoch 68/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0608 - accuracy: 0.9789\n","Epoch 69/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0598 - accuracy: 0.9783\n","Epoch 70/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0635 - accuracy: 0.9773\n","Epoch 71/100\n","1500/1500 [==============================] - 5s 4ms/step - loss: 0.0607 - accuracy: 0.9792\n","Epoch 72/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0580 - accuracy: 0.9788\n","Epoch 73/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0597 - accuracy: 0.9791\n","Epoch 74/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0573 - accuracy: 0.9799\n","Epoch 75/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0589 - accuracy: 0.9794\n","Epoch 76/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0587 - accuracy: 0.9802\n","Epoch 77/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0572 - accuracy: 0.9800\n","Epoch 78/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0593 - accuracy: 0.9794\n","Epoch 79/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0565 - accuracy: 0.9802\n","Epoch 80/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0545 - accuracy: 0.9802\n","Epoch 81/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0503 - accuracy: 0.9832\n","Epoch 82/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0513 - accuracy: 0.9819\n","Epoch 83/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0514 - accuracy: 0.9816\n","Epoch 84/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0511 - accuracy: 0.9819\n","Epoch 85/100\n","1500/1500 [==============================] - 7s 4ms/step - loss: 0.0525 - accuracy: 0.9815\n","Epoch 86/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0493 - accuracy: 0.9827\n","Epoch 87/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0459 - accuracy: 0.9841\n","Epoch 88/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0468 - accuracy: 0.9833\n","Epoch 89/100\n","1500/1500 [==============================] - 7s 4ms/step - loss: 0.0465 - accuracy: 0.9835\n","Epoch 90/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0479 - accuracy: 0.9831\n","Epoch 91/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0465 - accuracy: 0.9842\n","Epoch 92/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0459 - accuracy: 0.9842\n","Epoch 93/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0487 - accuracy: 0.9839\n","Epoch 94/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0438 - accuracy: 0.9844\n","Epoch 95/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0475 - accuracy: 0.9839\n","Epoch 96/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0467 - accuracy: 0.9840\n","Epoch 97/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0468 - accuracy: 0.9840\n","Epoch 98/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0426 - accuracy: 0.9851\n","Epoch 99/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0460 - accuracy: 0.9836\n","Epoch 100/100\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0441 - accuracy: 0.9850\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nplt.plot(history.history['loss'])\\nplt.xlabel('epoch')\\nplt.ylabel('loss')\\nplt.savefig('7_3-01', dpi=300)\\nplt.show()\\n\""]},"metadata":{},"execution_count":11}]}]}
